{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual metrics (Length, Boilerplate, Fog, Hardinfo, Redundancy, Stickiness)\n",
    "\n",
    "This notebook computes the metrics from your CSV reports. Each metric is computed in its own cell, and a summary table is produced at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "833d4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports and configuration.\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Update these two values to view metrics for a specific report\n",
    "TARGET_COMPANY = \"AFI\"\n",
    "TARGET_YEAR = 2020\n",
    "\n",
    "# Folder holding CSV files (per report or combined)\n",
    "REPORTS_DIR = Path(\"textual-metrics/reports\")\n",
    "if not REPORTS_DIR.exists():\n",
    "    REPORTS_DIR = Path(\"reports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3520831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1484 reports from 1484 CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Load report CSVs and build per-report sentence lists.\n",
    "def parse_company_year(value: str):\n",
    "    match = re.search(r\"([A-Za-z]+)(\\d{4})\", str(value))\n",
    "    if match:\n",
    "        return match.group(1).upper(), int(match.group(2))\n",
    "    return None, None\n",
    "\n",
    "csv_paths = sorted(REPORTS_DIR.glob(\"*.csv\"))\n",
    "if not csv_paths:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {REPORTS_DIR}\")\n",
    "\n",
    "frames = []\n",
    "for path in csv_paths:\n",
    "    df = pd.read_csv(path)\n",
    "    if \"sentence\" not in df.columns:\n",
    "        continue\n",
    "\n",
    "    file_company, file_year = parse_company_year(path.stem)\n",
    "    if not file_company or not file_year:\n",
    "        raise ValueError(f\"Could not parse company/year from filename: {path.name}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"company\"] = file_company\n",
    "    df[\"year\"] = file_year\n",
    "    frames.append(df)\n",
    "\n",
    "all_df = pd.concat(frames, ignore_index=True)\n",
    "if all_df[[\"company\", \"year\"]].isna().any().any():\n",
    "    raise ValueError(\"Could not parse company/year for some rows. Check filename pattern.\")\n",
    "\n",
    "reports = {}\n",
    "for (company, year), group in all_df.groupby([\"company\", \"year\"]):\n",
    "    sentences = group[\"sentence\"].dropna().astype(str).tolist()\n",
    "    reports[(company, int(year))] = sentences\n",
    "\n",
    "print(f\"Loaded {len(reports)} reports from {len(csv_paths)} CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fde0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helpers for tokenization, n-grams, syllables, and numeric filters.\n",
    "def words_in_text(text: str):\n",
    "    raw = []\n",
    "    for token in str(text).split():\n",
    "        token = token.strip(string.punctuation)\n",
    "        if token:\n",
    "            raw.append(token)\n",
    "\n",
    "    words = []\n",
    "    buffer = []\n",
    "    for token in raw:\n",
    "        if len(token) < 2:\n",
    "            buffer.append(token)\n",
    "            continue\n",
    "        if buffer:\n",
    "            if len(buffer) >= 2:\n",
    "                words.append(''.join(buffer))\n",
    "            else:\n",
    "                words.append(buffer[0])\n",
    "            buffer = []\n",
    "        words.append(token)\n",
    "\n",
    "    if buffer:\n",
    "        if len(buffer) >= 2:\n",
    "            words.append(''.join(buffer))\n",
    "        else:\n",
    "            words.append(buffer[0])\n",
    "\n",
    "    return words\n",
    "\n",
    "def normalized_words(text: str):\n",
    "    return [w.lower() for w in words_in_text(text)]\n",
    "\n",
    "def ngrams(words, n):\n",
    "    return [tuple(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "\n",
    "def count_syllables(word: str):\n",
    "    word = re.sub(r\"[^a-zA-Z]\", \"\", word).lower()\n",
    "    if not word:\n",
    "        return 0\n",
    "    vowels = \"aeiouy\"\n",
    "    count = 0\n",
    "    prev_vowel = False\n",
    "    for ch in word:\n",
    "        is_vowel = ch in vowels\n",
    "        if is_vowel and not prev_vowel:\n",
    "            count += 1\n",
    "        prev_vowel = is_vowel\n",
    "    if word.endswith(\"e\") and count > 1:\n",
    "        count -= 1\n",
    "    if word.endswith(\"le\") and len(word) > 2 and word[-3] not in vowels:\n",
    "        count += 1\n",
    "    return max(count, 1)\n",
    "\n",
    "DATE_PATTERNS = [\n",
    "    re.compile(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\b(?:jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[a-z]*\\s+\\d{1,2},?\\s+\\d{4}\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\b\\d{1,2}\\s+(?:jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[a-z]*\\s+\\d{4}\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\b(?:jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[a-z]*\\s+\\d{4}\\b\", re.IGNORECASE),\n",
    "]\n",
    "SECTION_PATTERNS = [\n",
    "    re.compile(r\"\\b\\d+(?:\\.\\d+)+\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bsection\\s+\\d+(?:\\.\\d+)*\\b\", re.IGNORECASE),\n",
    "]\n",
    "PAGE_PATTERNS = [\n",
    "    re.compile(r\"\\bpage\\s+\\d+\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bp\\.?\\s*\\d+\\b\", re.IGNORECASE),\n",
    "]\n",
    "NUMBER_PATTERN = re.compile(r\"\\b\\d{1,3}(?:,\\d{3})+(?:\\.\\d+)?\\b|\\b\\d+(?:\\.\\d+)?\\b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1de494e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length (AFI2020): 23.2700 (total_words=23270, denominator=1000)\n"
     ]
    }
   ],
   "source": [
    "# Compute Length for the selected report.\n",
    "def total_words(sentences):\n",
    "    return sum(len(words_in_text(s)) for s in sentences)\n",
    "\n",
    "sentences = reports.get((TARGET_COMPANY, TARGET_YEAR))\n",
    "if sentences is None:\n",
    "    raise KeyError(f\"Report not found for {TARGET_COMPANY}{TARGET_YEAR}\")\n",
    "\n",
    "total = total_words(sentences)\n",
    "length_metric = total / 1000 if total else 0\n",
    "print(f\"Length ({TARGET_COMPANY}{TARGET_YEAR}): {length_metric:.4f} (total_words={total}, denominator=1000)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d17a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boilerplate (AFI2020): 0.1372 (boilerplate_words=3193, total_words=23270)\n"
     ]
    }
   ],
   "source": [
    "# Compute Boilerplate for the selected report (year-level 75% rule).\n",
    "report_4grams = {}\n",
    "for (company, year), sents in reports.items():\n",
    "    grams = set()\n",
    "    for s in sents:\n",
    "        words = normalized_words(s)\n",
    "        grams.update(ngrams(words, 4))\n",
    "    report_4grams[(company, year)] = grams\n",
    "\n",
    "boilerplate_4grams_by_year = {}\n",
    "for year in sorted({yr for _, yr in reports.keys()}):\n",
    "    year_reports = [grams for (comp, yr), grams in report_4grams.items() if yr == year]\n",
    "    firm_count = len(year_reports)\n",
    "    if firm_count == 0:\n",
    "        boilerplate_4grams_by_year[year] = set()\n",
    "        continue\n",
    "    counts = Counter()\n",
    "    for grams in year_reports:\n",
    "        counts.update(grams)\n",
    "    threshold = math.ceil(0.75 * firm_count)\n",
    "    boilerplate_4grams_by_year[year] = {g for g, c in counts.items() if c >= threshold}\n",
    "\n",
    "def boilerplate_words(sentences, year):\n",
    "    boiler_grams = boilerplate_4grams_by_year.get(year, set())\n",
    "    count = 0\n",
    "    for s in sentences:\n",
    "        words = normalized_words(s)\n",
    "        sentence_grams = set(ngrams(words, 4))\n",
    "        if sentence_grams & boiler_grams:\n",
    "            count += len(words_in_text(s))\n",
    "    return count\n",
    "\n",
    "boiler_words = boilerplate_words(sentences, TARGET_YEAR)\n",
    "boiler_metric = (boiler_words / total) if total else 0\n",
    "print(f\"Boilerplate ({TARGET_COMPANY}{TARGET_YEAR}): {boiler_metric:.4f} (boilerplate_words={boiler_words}, total_words={total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97d66304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fog (AFI2020): 19.8375 (sentences=884, words=23270, complex_words=5415)\n"
     ]
    }
   ],
   "source": [
    "# Compute Fog index for the selected report (education level).\n",
    "def fog_index(sentences):\n",
    "    sentence_list = [s for s in sentences if words_in_text(s)]\n",
    "    if not sentence_list:\n",
    "        return None\n",
    "    words = [w for s in sentence_list for w in words_in_text(s)]\n",
    "    if not words:\n",
    "        return None\n",
    "    complex_count = sum(1 for w in words if count_syllables(w) >= 3)\n",
    "    # Fog = 0.4 * (ASL + 100 * PCW)\n",
    "    return 0.4 * ((len(words) / len(sentence_list)) + 100 * (complex_count / len(words)))\n",
    "\n",
    "fog_metric = fog_index(sentences)\n",
    "print(f\"Fog ({TARGET_COMPANY}{TARGET_YEAR}): {fog_metric:.4f} (sentences={len([s for s in sentences if words_in_text(s)])}, words={len([w for s in sentences for w in words_in_text(s)])}, complex_words={sum(1 for s in sentences for w in words_in_text(s) if count_syllables(w) >= 3)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8588dd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardinfo (AFI2020): 53.2875 (informative_numbers=1240, total_words=23270)\n"
     ]
    }
   ],
   "source": [
    "# Compute Hardinfo for the selected report (except for dates, sections, and page numbers).\n",
    "def hardinfo_count(sentences):\n",
    "    count = 0\n",
    "    for s in sentences:\n",
    "        cleaned = s\n",
    "        for pattern in DATE_PATTERNS + SECTION_PATTERNS + PAGE_PATTERNS:\n",
    "            cleaned = pattern.sub(\" \", cleaned)\n",
    "        count += len(NUMBER_PATTERN.findall(cleaned))\n",
    "    return count\n",
    "\n",
    "hardinfo = hardinfo_count(sentences)\n",
    "hardinfo_metric = (hardinfo / total) * 1000 if total else 0\n",
    "print(f\"Hardinfo ({TARGET_COMPANY}{TARGET_YEAR}): {hardinfo_metric:.4f} (informative_numbers={hardinfo}, total_words={total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23f2d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy (AFI2020): 0.1508 (redundant_words=3508, total_words=23270)\n"
     ]
    }
   ],
   "source": [
    "# Compute Redundancy for the selected report.\n",
    "def redundancy_words(sentences):\n",
    "    normalized = [str(s).strip() for s in sentences if str(s).strip()]\n",
    "    counts = Counter(normalized)\n",
    "    redundant = 0\n",
    "    for sentence, freq in counts.items():\n",
    "        if freq > 1:\n",
    "            redundant += freq * len(words_in_text(sentence))\n",
    "    return redundant\n",
    "\n",
    "redundant = redundancy_words(sentences)\n",
    "redundancy_metric = (redundant / total) if total else 0\n",
    "print(f\"Redundancy ({TARGET_COMPANY}{TARGET_YEAR}): {redundancy_metric:.4f} (redundant_words={redundant}, total_words={total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c08d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stickiness (AFI2020): 0.7744 (sticky_words=18020, total_words=23270)\n"
     ]
    }
   ],
   "source": [
    "# Compute Stickiness for the selected report using prior year.\n",
    "def report_8grams(sentences):\n",
    "    grams = set()\n",
    "    for s in sentences:\n",
    "        words = normalized_words(s)\n",
    "        grams.update(ngrams(words, 8))\n",
    "    return grams\n",
    "\n",
    "def sticky_words(sentences, prior_sentences):\n",
    "    prior_grams = report_8grams(prior_sentences)\n",
    "    count = 0\n",
    "    for s in sentences:\n",
    "        words = normalized_words(s)\n",
    "        if set(ngrams(words, 8)) & prior_grams:\n",
    "            count += len(words_in_text(s))\n",
    "    return count\n",
    "\n",
    "prior_report = reports.get((TARGET_COMPANY, TARGET_YEAR - 1))\n",
    "if prior_report is None:\n",
    "    stickiness_metric = None\n",
    "    print(f\"Stickiness ({TARGET_COMPANY}{TARGET_YEAR}): N/A (missing prior year report)\")\n",
    "else:\n",
    "    sticky = sticky_words(sentences, prior_report)\n",
    "    stickiness_metric = (sticky / total) if total else 0\n",
    "    print(f\"Stickiness ({TARGET_COMPANY}{TARGET_YEAR}): {stickiness_metric:.4f} (sticky_words={sticky}, total_words={total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ce5e7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>length</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>fog</th>\n",
       "      <th>hardinfo</th>\n",
       "      <th>redundancy</th>\n",
       "      <th>stickiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFI</td>\n",
       "      <td>2013</td>\n",
       "      <td>35.109</td>\n",
       "      <td>0.129767</td>\n",
       "      <td>20.309889</td>\n",
       "      <td>43.122846</td>\n",
       "      <td>0.098180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFI</td>\n",
       "      <td>2014</td>\n",
       "      <td>33.441</td>\n",
       "      <td>0.128256</td>\n",
       "      <td>20.437731</td>\n",
       "      <td>45.841931</td>\n",
       "      <td>0.106755</td>\n",
       "      <td>0.790407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFI</td>\n",
       "      <td>2015</td>\n",
       "      <td>26.904</td>\n",
       "      <td>0.104037</td>\n",
       "      <td>20.245238</td>\n",
       "      <td>50.773119</td>\n",
       "      <td>0.154252</td>\n",
       "      <td>0.633958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFI</td>\n",
       "      <td>2016</td>\n",
       "      <td>23.992</td>\n",
       "      <td>0.124083</td>\n",
       "      <td>19.677189</td>\n",
       "      <td>55.310103</td>\n",
       "      <td>0.130127</td>\n",
       "      <td>0.808269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFI</td>\n",
       "      <td>2017</td>\n",
       "      <td>17.438</td>\n",
       "      <td>0.118305</td>\n",
       "      <td>20.001296</td>\n",
       "      <td>50.865925</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.824406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>WHS</td>\n",
       "      <td>2021</td>\n",
       "      <td>39.299</td>\n",
       "      <td>0.127484</td>\n",
       "      <td>20.911034</td>\n",
       "      <td>26.616453</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.391104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>WHS</td>\n",
       "      <td>2022</td>\n",
       "      <td>41.885</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>21.185322</td>\n",
       "      <td>26.883132</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.439585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>WHS</td>\n",
       "      <td>2023</td>\n",
       "      <td>39.808</td>\n",
       "      <td>0.124548</td>\n",
       "      <td>20.663708</td>\n",
       "      <td>28.712822</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.457546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>WHS</td>\n",
       "      <td>2024</td>\n",
       "      <td>34.516</td>\n",
       "      <td>0.181046</td>\n",
       "      <td>20.716922</td>\n",
       "      <td>22.916908</td>\n",
       "      <td>0.199618</td>\n",
       "      <td>0.610181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>WHS</td>\n",
       "      <td>2025</td>\n",
       "      <td>56.900</td>\n",
       "      <td>0.042355</td>\n",
       "      <td>20.653497</td>\n",
       "      <td>49.138840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1484 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  year  length  boilerplate        fog   hardinfo  redundancy  \\\n",
       "0        AFI  2013  35.109     0.129767  20.309889  43.122846    0.098180   \n",
       "1        AFI  2014  33.441     0.128256  20.437731  45.841931    0.106755   \n",
       "2        AFI  2015  26.904     0.104037  20.245238  50.773119    0.154252   \n",
       "3        AFI  2016  23.992     0.124083  19.677189  55.310103    0.130127   \n",
       "4        AFI  2017  17.438     0.118305  20.001296  50.865925    0.010322   \n",
       "...      ...   ...     ...          ...        ...        ...         ...   \n",
       "1479     WHS  2021  39.299     0.127484  20.911034  26.616453    0.006158   \n",
       "1480     WHS  2022  41.885     0.130405  21.185322  26.883132    0.013083   \n",
       "1481     WHS  2023  39.808     0.124548  20.663708  28.712822    0.004070   \n",
       "1482     WHS  2024  34.516     0.181046  20.716922  22.916908    0.199618   \n",
       "1483     WHS  2025  56.900     0.042355  20.653497  49.138840    1.000000   \n",
       "\n",
       "      stickiness  \n",
       "0            NaN  \n",
       "1       0.790407  \n",
       "2       0.633958  \n",
       "3       0.808269  \n",
       "4       0.824406  \n",
       "...          ...  \n",
       "1479    0.391104  \n",
       "1480    0.439585  \n",
       "1481    0.457546  \n",
       "1482    0.610181  \n",
       "1483    0.044851  \n",
       "\n",
       "[1484 rows x 8 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build summary table for all reports.\n",
    "records = []\n",
    "for (company, year), sents in reports.items():\n",
    "    total = total_words(sents)\n",
    "    length_metric = total / 1000 if total else 0\n",
    "    boiler_words = boilerplate_words(sents, year)\n",
    "    boiler_metric = (boiler_words / total) if total else 0\n",
    "    fog_metric = fog_index(sents)\n",
    "    hardinfo = hardinfo_count(sents)\n",
    "    hardinfo_metric = (hardinfo / total) * 1000 if total else 0\n",
    "    redundant = redundancy_words(sents)\n",
    "    redundancy_metric = (redundant / total) if total else 0\n",
    "    prior = reports.get((company, year - 1))\n",
    "    if prior is None:\n",
    "        stickiness_metric = None\n",
    "    else:\n",
    "        sticky = sticky_words(sents, prior)\n",
    "        stickiness_metric = (sticky / total) if total else 0\n",
    "\n",
    "    records.append({\n",
    "        \"company\": company,\n",
    "        \"year\": year,\n",
    "        \"length\": length_metric,\n",
    "        \"boilerplate\": boiler_metric,\n",
    "        \"fog\": fog_metric,\n",
    "        \"hardinfo\": hardinfo_metric,\n",
    "        \"redundancy\": redundancy_metric,\n",
    "        \"stickiness\": stickiness_metric,\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(records).sort_values([\"company\", \"year\"]).reset_index(drop=True)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed3bf28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to textual-metrics/outputs/textual_metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Save summary to CSV.\n",
    "output_dir = Path(\"textual-metrics/outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_path = output_dir / \"textual_metrics_summary.csv\"\n",
    "summary.to_csv(output_path, index=False)\n",
    "print(f\"Saved summary to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
